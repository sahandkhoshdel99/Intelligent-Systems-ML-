{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperation_index(data, cluster_indices, p = 2):\n",
    "Receives data and corresponding cluster indices, calculates seperation index using inter and intra distance, p indicates the distance order for p-norm distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperation_index(data, cluster_indices, p = 2):\n",
    "\n",
    "    def intra_distance(cluster, p = 2): #Calculates maximum intra-cluster distance\n",
    "        \n",
    "        if(p ==2):\n",
    "            return np.amax(pairwise_distances(cluster, metric = \"euclidean\"))\n",
    "        \n",
    "        else:\n",
    "            pairwise = np.zeros((len(cluster), len(cluster)))\n",
    "            for i in range(len(cluster)):\n",
    "                for j in range(len(cluster)):\n",
    "                    pairwise[i][j] = np.linalg.norm(cluster[i] - cluster[j], p)\n",
    "        return np.amax(pairwise)\n",
    "        \n",
    "    def inter_distance(cluster1, cluster2, p = 2):  #Calculates minimum inter-cluster distance (single-link)\n",
    "        x = np.zeros((len(cluster1), len(cluster2)))\n",
    "        x = [[np.linalg.norm(cluster1[i]-cluster2[j], p) for i in range(len(cluster1)) ] for j in range(len(cluster2))]\n",
    "        return np.amin(x)\n",
    "    \n",
    "        \n",
    "    num_clusters = len(np.unique(cluster_indices))\n",
    "    cluster_mapping = {} # Dictinary; Partitioning data based on cluster indices\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        cluster_mapping[np.unique(cluster_indices)[i]] = data[np.where(cluster_indices == i)]\n",
    "\n",
    "\n",
    "    temp = []\n",
    "    if(num_clusters == 1):\n",
    "        return 0\n",
    "    \n",
    "    for j in range(num_clusters):\n",
    "        \n",
    "        inner_temp = []\n",
    "        for i in range(num_clusters):\n",
    "            if(i!=j):# Iterating over other clusters after fixing one cluster\n",
    "                \n",
    "                # Higher Seperation for Algorithm with further clusters:\n",
    "                num = inter_distance(data[np.where(cluster_indices ==i)], data[np.where(cluster_indices ==j)], p) \n",
    "               \n",
    "                # Higher Seperation for Algorithm with denser clusters \n",
    "                den = np.amax([intra_distance(data[np.where(cluster_indices ==l)], p)  for l in range(num_clusters)]) #\n",
    "                \n",
    "                # Normalizing numerators across the whole cluster pairs with the denumerator \n",
    "                inner_temp.append(num/den) \n",
    "                \n",
    "    temp.append(min(inner_temp)) \n",
    "\n",
    "    seperation_index = min(temp) # Assuming a pessimistic lowerbound along the seperation metric for all pairs\n",
    "\n",
    "    return seperation_index\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fisher_index(data, cluster_indices):\n",
    "Receives data and corresponding cluster indices, calculates fisher discrimination index (FDI) using inter and intra distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_index(data, cluster_indices):\n",
    "    num_clusters = len(np.unique(cluster_indices))\n",
    "    data_dimension = len(data[0])\n",
    "    \n",
    "    epsilon = (np.amax(data)-np.amin(data))/(10**5) # Preventing Singularity of Sw\n",
    "    clusters = {} # Dictinary; Partitioning data based on cluster indices\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        clusters[np.unique(cluster_indices)[i]] = data[np.where(cluster_indices == i)]\n",
    "\n",
    "    #if(num_clusters==1):\n",
    "        #return 0\n",
    "    \n",
    "    centroids = []\n",
    "    \n",
    "    Sw = np.zeros((data_dimension, data_dimension))\n",
    "    for i in range(len(clusters)):\n",
    "        Si = np.zeros((data_dimension, data_dimension))\n",
    "        for q in range(len(clusters[i])):\n",
    "            \n",
    "            # Calculating Variance Matrix to obtain Si & Sw\n",
    "            mul = np.matmul(np.transpose(np.array([clusters[i][q] - np.mean(clusters[i][q])])), np.array([clusters[i][q] - np.mean(clusters[i][q])]))\n",
    "            Si = np.add(Si, mul)\n",
    "            \n",
    "        centroids.append(np.mean(clusters[i], axis = 0)) # Calculating Clusters Centroids\n",
    "    Sw = np.add(Sw, Si)\n",
    "    \n",
    "    \n",
    "    total_centroid  = np.mean(centroids, axis = 0) # Calculating Between Cluster Covariability using Centroids Covariance Matrix\n",
    "    Sb = np.zeros((data_dimension, data_dimension))\n",
    "    \n",
    "    for i in range(num_clusters):\n",
    "        Sb = np.add(Sb, np.matmul(np.transpose(np.array([(centroids[i] - (total_centroid))])), np.array([(centroids[i] - (total_centroid))])))\n",
    "    \n",
    "    Sw = np.add(Sw, epsilon*np.eye(data_dimension))\n",
    "    FDI = np.trace(np.matmul(np.linalg.inv(Sw), Sb)) \n",
    "    return FDI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### barchart_comparison(algorithms, seperations, fdis)\n",
    "Used for Clustering Comparison among rival algorithms.\n",
    "Receives Alg. names as a list of strings, and their corresponding seperation and fdi index as a list(numpy array) of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barchart_comparison(algorithms, seperations, fdis, clr = '#7756a7', title = None): #Gets list of Algorithm Names and Corresponding Seo, Fisher Metrics\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (20, 7))\n",
    "    fig.tight_layout(pad = 10.0)\n",
    "\n",
    "    y_pos = np.arange(len(algorithms))\n",
    "    ax[0].barh(algorithms, seperations, color = clr)\n",
    "    ax[0].set_xlabel('Seperation Indices')\n",
    "\n",
    "    ax[1].barh(algorithms, fdis, color = clr)\n",
    "    ax[1].set_xlabel('FDI')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using an exmaple\n",
    "#### Cluster1: (-2, -2), (-1,1),  Cluster2: (1,1), (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seperation Index: 2.0\n",
      "Fisher Index: 224999.99999999997\n"
     ]
    }
   ],
   "source": [
    "data = np.array(([-2,-2], [-1,-1], [1,1], [2,2]))\n",
    "cluster_index =np.array(([0,0,1,1]))\n",
    "\n",
    "print(f\"Seperation Index: {seperation_index(data, cluster_index)}\")\n",
    "print(f\"Fisher Index: {fisher_index(data, cluster_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
